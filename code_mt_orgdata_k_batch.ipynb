{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "88e4ba19-2b59-45c9-af08-677f62160b78",
   "metadata": {},
   "source": [
    "## import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c1adf1e-166c-4ebb-866f-e250b92a0d1a",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import random\n",
    "import network_fcn as vae\n",
    "import SiameseNetwork as smsn\n",
    "import argparse\n",
    "import pickle\n",
    "from keras.layers import concatenate, Flatten\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import tensorflow.keras.backend as K\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "import pickle\n",
    "from scipy import spatial\n",
    "import os\n",
    "from os.path import dirname, abspath\n",
    "from utils import *\n",
    "from itertools import combinations\n",
    "import warnings\n",
    "import Classify as cls\n",
    "from modeltransfer import *\n",
    "import matplotlib.colors as mcolors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e53f4840-423d-48b2-be62-fc04fcd05685",
   "metadata": {},
   "source": [
    "## configure GPU for tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8829c2d2-ec42-4af6-92ce-62c257ff2f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "physical_devices = tf.config.list_physical_devices('GPU') \n",
    "for gpu_instance in physical_devices: \n",
    "    tf.config.experimental.set_memory_growth(gpu_instance, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "628f7fc7-77c5-4fcf-88b0-dff972ba3a6f",
   "metadata": {},
   "source": [
    "## initialize hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5181bc3-965d-499f-af8e-9fb726a4ba36",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser(description='')\n",
    "parser.add_argument('--input_size', dest='input_size', default= (None, 1))\n",
    "parser.add_argument('--batch_shape', dest='batch_shape', default=8)\n",
    "parser.add_argument('--latent_shape', dest='latent_shape', default=128)\n",
    "parser.add_argument('--para_shape', dest='para_shape', default=15)\n",
    "parser.add_argument('--batch_size', dest='batch_size', type=int, default=64)\n",
    "parser.add_argument('--epochs', dest='epochs', type=int, default=50)\n",
    "parser.add_argument('--step_decay', dest='step_decay', type=int, default=5)\n",
    "parser.add_argument('--patience', dest='patience', type=int, default=10)\n",
    "parser.add_argument('--lr', dest='lr', type=float, default=0.00005)\n",
    "parser.add_argument('--dec_loss', dest='dec_loss', default=vae.loss().loss_vae)\n",
    "parser.add_argument('--dis_loss', dest='dis_loss', default=vae.loss().loss_bce)\n",
    "parser.add_argument('--cls_loss', dest='cls_loss', default=vae.loss().loss_bce)\n",
    "parser.add_argument('--beta_1', dest='beta_1', type=float, default=0.5)\n",
    "parser.add_argument('--norm', dest='norm', default='batch_norm')\n",
    "parser.add_argument('--n_down', dest='n_down', default=7)\n",
    "parser.add_argument('--n_std', dest='n_std', default=0.15)\n",
    "parser.add_argument('--batch', dest='batch', default=False)\n",
    "parser.add_argument('--group', dest='group', default=False)\n",
    "parser.add_argument('--n_group', dest='n_group', default=4)\n",
    "args, unknown = parser.parse_known_args()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83552bfe-0036-4d82-8aa2-9742f919c49d",
   "metadata": {},
   "source": [
    "## import data and remove spectra with much lower correlation than the others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "240d4cbd-6ffa-496d-8423-cabe5e0921f7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "metadata = pd.read_csv(dirname(abspath(os.getcwd())) + '/datasets/bacterial_SSP/metadata.csv')\n",
    "spec = pd.read_csv(dirname(abspath(os.getcwd())) + '/datasets/bacterial_SSP/data.csv')\n",
    "wn = np.array(spec.iloc[0,1:])\n",
    "spec = np.array(spec.iloc[1:,1:])\n",
    "labels = np.array(metadata['labels'])\n",
    "batches = np.array(metadata['batches'])\n",
    "\n",
    "ix_wn = np.asarray(range(len(wn)))[(wn>1850) & (wn<2750)]\n",
    "ix_wn1 = np.asarray(range(len(wn)))[(wn<1800) | (wn>2800)]\n",
    "\n",
    "for i in range(spec.shape[0]):\n",
    "    spec[i,:] = spec[i, :]/np.max(spec[i, :])\n",
    "\n",
    "ix = np.argwhere((labels != 'L-innocua') & (labels != 'P-stutzeri'))[:,0]\n",
    "spec = spec[ix, :]\n",
    "labels = labels[ix]\n",
    "batches = batches[ix]\n",
    "\n",
    "corr_all = np.mean(np.corrcoef(spec), 0)\n",
    "i_good = corr_all>np.percentile(corr_all, 1)\n",
    "spec = spec[i_good, :]\n",
    "labels = labels[i_good]\n",
    "batches = batches[i_good]\n",
    "\n",
    "uni_labels = np.unique(labels)\n",
    "dummy_y = np.zeros((len(labels), len(uni_labels)))\n",
    "for i in range(len(uni_labels)):\n",
    "    dummy_y[labels==uni_labels[i], i] = 1\n",
    "\n",
    "n_spec_gen = 60"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93c238ef-8ea3-4c00-a52f-55be7c5e2e26",
   "metadata": {},
   "source": [
    "## perform spectra generation and model transfer\n",
    "- perform model transfer on real data with different number of training samples\n",
    "- perform model transfer with different approaches: EMSC, MS, and siamese network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45efcdd9-487f-4a54-9ffb-47f42f7dbcdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "uni_batches = np.unique(batches)\n",
    "index = np.array(range(len(uni_batches)))\n",
    "for n_b in [2, 5, 8]:    ### number of batches for training\n",
    "    accs = []; \n",
    "    b_tests = []; \n",
    "    methods = [];\n",
    "    val_cors = []; \n",
    "    b_trains = [];\n",
    "    for ib_test in range(len(uni_batches)):\n",
    "        ix_test_spec = np.array(np.argwhere(batches==uni_batches[ib_test])[:, 0])\n",
    "        \n",
    "        b_sel = np.resize(True, len(uni_batches))\n",
    "        b_sel[ib_test] = False\n",
    "        \n",
    "        bat = []\n",
    "        for k in combinations(index[b_sel], n_b):\n",
    "            bat.append(k)\n",
    "        bat = np.row_stack(bat)\n",
    "        bat = bat[np.array(range(0, bat.shape[0], np.max([1, bat.shape[0]//9]))), :]\n",
    "    \n",
    "    # for kk in range(bat.shape[0]):\n",
    "        kk = 0\n",
    "        k = bat[0,:]   ### get the training batches\n",
    "        print(k)\n",
    "        batch_sel = np.array([uni_batches[i] for i in k])\n",
    "        \n",
    "        ix = [] \n",
    "        for b in batch_sel:\n",
    "            if len(ix)<1:\n",
    "                ix = (batches==b)\n",
    "            else:\n",
    "                ix = (ix) | (batches==b)\n",
    "        ix = np.array(np.argwhere(ix==True)[:,0])\n",
    "        \n",
    "        ix_test_spec = np.array(list(set(range(spec.shape[0])) - set(ix)))\n",
    "\n",
    "        #### normal classification without model transfer\n",
    "        model = cls.Classify(np.concatenate([spec[ix, :], spec[ix_test_spec, :]], axis=0), np.append(labels[ix], labels[ix_test_spec]), np.append(batches[ix], batches[ix_test_spec]))\n",
    "        pred = model.model(range(len(ix)), range(len(ix), len(ix)+len(ix_test_spec)))\n",
    "        acc = cls.cal_metric(labels[ix_test_spec], pred, batches[ix_test_spec])\n",
    "        accs = np.append(accs, acc) \n",
    "        b_tests = np.append(b_tests, np.unique(batches[ix_test_spec]))\n",
    "        methods = np.append(methods, np.resize('org', len(acc)))\n",
    "        b_trains = np.append(b_trains, np.resize(kk, len(acc)))\n",
    "\n",
    "        ### do model transfer based on MS\n",
    "        model = cls.Classify(np.concatenate([spec[ix, :], spec[ix_test_spec, :]], axis=0), np.append(labels[ix], labels[ix_test_spec]), np.append(batches[ix], batches[ix_test_spec]), True)\n",
    "        pred = model.model(range(len(ix)), range(len(ix), len(ix)+len(ix_test_spec)))\n",
    "        acc = cls.cal_metric(labels[ix_test_spec], pred, batches[ix_test_spec])\n",
    "        accs = np.append(accs, acc) \n",
    "        b_tests = np.append(b_tests, np.unique(batches[ix_test_spec]))\n",
    "        methods = np.append(methods, np.resize('MS', len(acc)))\n",
    "        b_trains = np.append(b_trains, np.resize(kk, len(acc)))\n",
    "        \n",
    "        ### do model transfer based on EMSC\n",
    "        interference, _ = cls.get_meanspec(np.concatenate([spec[ix, :], spec[ix_test_spec, :]], axis=0), labels=np.append(np.resize('org', len(ix)), np.resize('test', len(ix_test_spec))))\n",
    "        ### EMSC with one component\n",
    "        cur_spec_corr1 = emsc(np.concatenate([spec[ix, :], spec[ix_test_spec, :]], axis=0), degree=2, interferent=interference, interf_pca=1)['corrected']                \n",
    "        model = cls.Classify(cur_spec_corr1, np.append(labels[ix], labels[ix_test_spec]), np.append(batches[ix], batches[ix_test_spec]))\n",
    "        pred = model.model(range(len(ix)), range(len(ix), len(ix)+len(ix_test_spec)))\n",
    "        acc = cls.cal_metric(labels[ix_test_spec], pred, batches[ix_test_spec])\n",
    "        accs = np.append(accs, acc) \n",
    "        b_tests = np.append(b_tests, np.unique(batches[ix_test_spec]))\n",
    "        methods = np.append(methods, np.resize('EMSC1', len(acc)))\n",
    "        b_trains = np.append(b_trains, np.resize(kk, len(acc)))\n",
    "        ### EMSC with two components\n",
    "        cur_spec_corr2 = emsc(np.concatenate([spec[ix, :], spec[ix_test_spec, :]], axis=0), degree=2, interferent=interference, interf_pca=2)['corrected']                \n",
    "        model = cls.Classify(cur_spec_corr2, np.append(labels[ix], labels[ix_test_spec]), np.append(batches[ix], batches[ix_test_spec]))\n",
    "        pred = model.model(range(len(ix)), range(len(ix), len(ix)+len(ix_test_spec)))\n",
    "        acc = cls.cal_metric(labels[ix_test_spec], pred, batches[ix_test_spec])\n",
    "        accs = np.append(accs, acc) \n",
    "        b_tests = np.append(b_tests, np.unique(batches[ix_test_spec]))\n",
    "        methods = np.append(methods, np.resize('EMSC2', len(acc)))\n",
    "        b_trains = np.append(b_trains, np.resize(kk, len(acc)))\n",
    "        \n",
    "        ### randomly choose from training data spectra to perform prediction with siamese network \n",
    "        smp_train = []\n",
    "        for l in np.unique(labels[ix]):\n",
    "            smp_train = np.append(smp_train, np.random.choice(ix[np.argwhere(labels[ix]==l)[:,0]], 10, replace=False))\n",
    "        smp_train = np.array(smp_train, dtype='int32')\n",
    "        \n",
    "        args.batch=False; args.lr=0.00001\n",
    "        args.input_size = (spec.shape[1], 1)   \n",
    "        args.epochs=200\n",
    "        m_nn = smsn.SiameseNetwork(args)    \n",
    "        m_nn.train_cls(spec[ix, :], dummy_y[ix, :])   ### train ordinary neural network\n",
    "        pred_test, acc, min_acc, std_acc, method, b_test = m_nn.pred_cls(spec[ix_test_spec, :], labels[ix_test_spec], batches[ix_test_spec], uni_labels)\n",
    "        accs = np.append(accs, acc) \n",
    "        b_tests = np.append(b_tests, np.unique(batches[ix_test_spec]))\n",
    "        methods = np.append(methods, np.resize('nn', len(acc)))\n",
    "        b_trains = np.append(b_trains, np.resize(kk, len(acc)))\n",
    "    \n",
    "        n_pairs=40000\n",
    "        x, y, cb, g = prep_training_cls(spec[ix,:], labels[ix], batches[ix], n_pairs, cb_shape=args.batch_shape)\n",
    "        \n",
    "        args.batch=False; args.group=False; args.lr=0.00001\n",
    "        args.epochs=100\n",
    "        m_smsn = smsn.SiameseNetwork(args)\n",
    "        m_smsn.train_snet(x, y, g, cb, f_model='_weights.h5')  ### train siamese neural network\n",
    "        ### predict spectra without EMSC\n",
    "        pred_test, acc, min_acc, std_acc, method, b_test = m_smsn.pred_snet(spec[smp_train,:], labels[smp_train], spec[ix_test_spec, :], labels[ix_test_spec], batches[ix_test_spec])\n",
    "        accs = np.append(accs, acc) \n",
    "        b_tests = np.append(b_tests, np.unique(batches[ix_test_spec]))\n",
    "        methods = np.append(methods, np.resize('snet', len(acc)))\n",
    "        b_trains = np.append(b_trains, np.resize(kk, len(acc)))\n",
    "\n",
    "        ### predict spectra with EMSC\n",
    "        pred_test, acc, min_acc, std_acc, method, b_test = m_smsn.pred_snet(spec[smp_train,:], labels[smp_train], cur_spec_corr1[ix_test_spec, :], labels[ix_test_spec], batches[ix_test_spec])\n",
    "        accs = np.append(accs, acc) \n",
    "        b_tests = np.append(b_tests, np.unique(batches[ix_test_spec]))\n",
    "        methods = np.append(methods, np.resize('snet-EMSC1', len(acc)))\n",
    "        b_trains = np.append(b_trains, np.resize(kk, len(acc)))\n",
    "\n",
    "        args.batch=False; args.group=True; args.lr=0.00001\n",
    "        args.epochs=100\n",
    "        m_smsn = smsn.SiameseNetwork(args)\n",
    "        m_smsn.train_snet(x, y, g, cb, f_model='_weights.h5') ### train siamese neural network (batch-loss)\n",
    "        \n",
    "        ### predict spectra without EMSC\n",
    "        pred_test, acc, min_acc, std_acc, method, b_test = m_smsn.pred_snet(spec[smp_train,:], labels[smp_train], spec[ix_test_spec, :], labels[ix_test_spec], batches[ix_test_spec])\n",
    "        accs = np.append(accs, acc) \n",
    "        b_tests = np.append(b_tests, np.unique(batches[ix_test_spec]))\n",
    "        methods = np.append(methods, np.resize('snet-g', len(acc)))\n",
    "        b_trains = np.append(b_trains, np.resize(kk, len(acc)))\n",
    "\n",
    "        ### predict spectra with EMSC\n",
    "        pred_test, acc, min_acc, std_acc, method, b_test = m_smsn.pred_snet(spec[smp_train,:], labels[smp_train], cur_spec_corr1[ix_test_spec, :], labels[ix_test_spec], batches[ix_test_spec])\n",
    "        accs = np.append(accs, acc) \n",
    "        b_tests = np.append(b_tests, np.unique(batches[ix_test_spec]))\n",
    "        methods = np.append(methods, np.resize('snet-g-EMSC1', len(acc)))\n",
    "        b_trains = np.append(b_trains, np.resize(kk, len(acc)))\n",
    "        \n",
    "        args.batch=True; args.group=False; args.lr=0.00001\n",
    "        m_smsn = smsn.SiameseNetwork(args)\n",
    "        m_smsn.train_snet(x, y, g, cb, f_model='_weights.h5') ### train siamese neural network (group-loss)\n",
    "        ### predict spectra without EMSC\n",
    "        pred_test, acc, min_acc, std_acc, method, b_test = m_smsn.pred_snet(spec[smp_train,:], labels[smp_train], spec[ix_test_spec, :], labels[ix_test_spec], batches[ix_test_spec])\n",
    "        accs = np.append(accs, acc) \n",
    "        b_tests = np.append(b_tests, np.unique(batches[ix_test_spec]))\n",
    "        methods = np.append(methods, np.resize('snet-b', len(acc)))\n",
    "        b_trains = np.append(b_trains, np.resize(kk, len(acc)))\n",
    "\n",
    "        ### predict spectra with EMSC\n",
    "        pred_test, acc, min_acc, std_acc, method, b_test = m_smsn.pred_snet(spec[smp_train,:], labels[smp_train], cur_spec_corr1[ix_test_spec, :], labels[ix_test_spec], batches[ix_test_spec])\n",
    "        accs = np.append(accs, acc) \n",
    "        b_tests = np.append(b_tests, np.unique(batches[ix_test_spec]))\n",
    "        methods = np.append(methods, np.resize('snet-b-EMSC1', len(acc)))\n",
    "        b_trains = np.append(b_trains, np.resize(kk, len(acc)))\n",
    "\n",
    "        args.batch=True; args.group=True; args.lr=0.00001\n",
    "        m_smsn = smsn.SiameseNetwork(args)\n",
    "        m_smsn.train_snet(x, y, g, cb, f_model='_weights.h5') ### train siamese neural network (group- and batch-loss)\n",
    "        ### predict spectra without EMSC\n",
    "        pred_test, acc, min_acc, std_acc, method, b_test = m_smsn.pred_snet(spec[smp_train,:], labels[smp_train], spec[ix_test_spec, :], labels[ix_test_spec], batches[ix_test_spec])\n",
    "        accs = np.append(accs, acc) \n",
    "        b_tests = np.append(b_tests, np.unique(batches[ix_test_spec]))\n",
    "        methods = np.append(methods, np.resize('snet-gb', len(acc)))\n",
    "        b_trains = np.append(b_trains, np.resize(kk, len(acc)))\n",
    "\n",
    "        ### predict spectra with EMSC\n",
    "        pred_test, acc, min_acc, std_acc, method, b_test = m_smsn.pred_snet(spec[smp_train,:], labels[smp_train], cur_spec_corr1[ix_test_spec, :], labels[ix_test_spec], batches[ix_test_spec])\n",
    "        accs = np.append(accs, acc) \n",
    "        b_tests = np.append(b_tests, np.unique(batches[ix_test_spec]))\n",
    "        methods = np.append(methods, np.resize('snet-gb-EMSC1', len(acc)))\n",
    "        b_trains = np.append(b_trains, np.resize(kk, len(acc)))\n",
    "\n",
    "    db_methods = ['org', 'nn', 'snet', 'snet-b', 'snet-g', 'snet-gb', 'MS', 'EMSC1', 'EMSC2', 'snet-EMSC1', 'snet-g-EMSC1', 'snet-b-EMSC1', 'snet-gb-EMSC1']\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(5, 5))\n",
    "    cols = list(mcolors.TABLEAU_COLORS)\n",
    "    acc_all = []\n",
    "    for i in range(len(db_methods)):\n",
    "        for j in range(len(uni_batches)):\n",
    "            acc_all = np.append(acc_all, np.mean(accs[(methods==db_methods[i]) & (b_tests==uni_batches[j])]))\n",
    "    acc_all = np.reshape(acc_all, (len(db_methods), len(uni_batches)))\n",
    "    sns.boxplot(data=acc_all.T, width=0.5, ax=ax)\n",
    "    ax.set_xticks(range(len(db_methods)), db_methods, rotation=-45)\n",
    "    ax.set_ylabel('balanced accuracy')\n",
    "    ax.set_title('Cross-Batch on Real Data')  \n",
    "    plt.show()\n",
    "    \n",
    "    with open(dirname(abspath(os.getcwd())) + '/results/accs_mt1_org_' + str(n_b) + '_Batch.pkl', 'wb') as f:\n",
    "        pickle.dump([accs, methods, b_trains, b_tests], f)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d5a5549-2b73-4d6e-9582-99232c1270b4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
