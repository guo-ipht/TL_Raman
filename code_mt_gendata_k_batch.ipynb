{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "34c6be91-2173-44d3-afd5-a7bde306be65",
   "metadata": {},
   "source": [
    "## import important packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c1adf1e-166c-4ebb-866f-e250b92a0d1a",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import random\n",
    "import network_fcn as vae\n",
    "import SiameseNetwork as smsn\n",
    "import argparse\n",
    "import pickle\n",
    "from keras.layers import concatenate, Flatten\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import tensorflow.keras.backend as K\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "import pickle\n",
    "from scipy import spatial\n",
    "import os\n",
    "from os.path import dirname, abspath\n",
    "from utils import *\n",
    "from itertools import combinations\n",
    "import warnings\n",
    "import Classify as cls\n",
    "from modeltransfer import *\n",
    "import matplotlib.colors as mcolors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d0138f9-67dc-4cf3-9b3d-21e1456ee1f5",
   "metadata": {},
   "source": [
    "## set GPU environment for tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8829c2d2-ec42-4af6-92ce-62c257ff2f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "physical_devices = tf.config.list_physical_devices('GPU') \n",
    "for gpu_instance in physical_devices: \n",
    "    tf.config.experimental.set_memory_growth(gpu_instance, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "628f7fc7-77c5-4fcf-88b0-dff972ba3a6f",
   "metadata": {},
   "source": [
    "## initialize hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5181bc3-965d-499f-af8e-9fb726a4ba36",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser(description='')\n",
    "parser.add_argument('--input_size', dest='input_size', default= (None, 1))\n",
    "parser.add_argument('--batch_shape', dest='batch_shape', default=8)\n",
    "parser.add_argument('--latent_shape', dest='latent_shape', default=128)\n",
    "parser.add_argument('--para_shape', dest='para_shape', default=15)\n",
    "parser.add_argument('--batch_size', dest='batch_size', type=int, default=64)\n",
    "parser.add_argument('--epochs', dest='epochs', type=int, default=50)\n",
    "parser.add_argument('--step_decay', dest='step_decay', type=int, default=5)\n",
    "parser.add_argument('--patience', dest='patience', type=int, default=10)\n",
    "parser.add_argument('--lr', dest='lr', type=float, default=0.00005)\n",
    "parser.add_argument('--dec_loss', dest='dec_loss', default=vae.loss().loss_vae)\n",
    "parser.add_argument('--dis_loss', dest='dis_loss', default=vae.loss().loss_bce)\n",
    "parser.add_argument('--cls_loss', dest='cls_loss', default=vae.loss().loss_bce)\n",
    "parser.add_argument('--beta_1', dest='beta_1', type=float, default=0.5)\n",
    "parser.add_argument('--norm', dest='norm', default='batch_norm')\n",
    "parser.add_argument('--n_down', dest='n_down', default=7)\n",
    "parser.add_argument('--n_std', dest='n_std', default=0.15)\n",
    "parser.add_argument('--batch', dest='batch', default=False)\n",
    "parser.add_argument('--group', dest='group', default=False)\n",
    "parser.add_argument('--n_group', dest='n_group', default=4)\n",
    "args, unknown = parser.parse_known_args()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a86edd8-0c1e-43bd-8e8f-a210a4af05f7",
   "metadata": {},
   "source": [
    "## import data and perform normalization, remove spectra with too low conrrelation compared to the other spectra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "240d4cbd-6ffa-496d-8423-cabe5e0921f7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "metadata = pd.read_csv(dirname(abspath(os.getcwd())) + '/datasets/bacterial_SSP/metadata.csv')\n",
    "spec = pd.read_csv(dirname(abspath(os.getcwd())) + '/datasets/bacterial_SSP/data.csv')\n",
    "wn = np.array(spec.iloc[0,1:])\n",
    "spec = np.array(spec.iloc[1:,1:])\n",
    "labels = np.array(metadata['labels'])\n",
    "batches = np.array(metadata['batches'])\n",
    "\n",
    "ix_wn = np.asarray(range(len(wn)))[(wn>1850) & (wn<2750)]\n",
    "ix_wn1 = np.asarray(range(len(wn)))[(wn<1800) | (wn>2800)]\n",
    "\n",
    "for i in range(spec.shape[0]):\n",
    "    spec[i,:] = spec[i, :]/np.max(spec[i, :])\n",
    "\n",
    "ix = np.argwhere((labels != 'L-innocua') & (labels != 'P-stutzeri'))[:,0]\n",
    "spec = spec[ix, :]\n",
    "labels = labels[ix]\n",
    "batches = batches[ix]\n",
    "\n",
    "corr_all = np.mean(np.corrcoef(spec), 0)\n",
    "i_good = corr_all>np.percentile(corr_all, 1)\n",
    "spec = spec[i_good, :]\n",
    "labels = labels[i_good]\n",
    "batches = batches[i_good]\n",
    "\n",
    "uni_labels = np.unique(labels)\n",
    "dummy_y = np.zeros((len(labels), len(uni_labels)))\n",
    "for i in range(len(uni_labels)):\n",
    "    dummy_y[labels==uni_labels[i], i] = 1\n",
    "\n",
    "n_spec_gen = 60"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0efbae4f-28ea-4d09-8166-44792eb44d1c",
   "metadata": {},
   "source": [
    "## perform spectra generation and model transfer\n",
    "- generate spectra for different spectral variations and in case of different training data sizes\n",
    "- perform model transfer, i.e, train with real data, and predict generated data.\n",
    "- model transfer is achieved with different methods: EMSC, MS, and siamese network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45efcdd9-487f-4a54-9ffb-47f42f7dbcdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "uni_batches = np.unique(batches)\n",
    "index = np.array(range(len(uni_batches)))\n",
    "for n_b in [2, 5, 8]:    ### number of batches for training\n",
    "\n",
    "    accs = []; \n",
    "    b_tests = []; \n",
    "    methods = [];\n",
    "    val_cors = []; \n",
    "    b_trains = [];\n",
    "        \n",
    "    bat = []\n",
    "    for k in combinations(index, n_b):\n",
    "        bat.append(k)\n",
    "    bat = np.row_stack(bat)\n",
    "    bat = bat[np.array(range(0, bat.shape[0], np.max([1, bat.shape[0]//9]))), :]\n",
    "    \n",
    "    for kk in range(bat.shape[0]):    ### index of batches to be used for training\n",
    "        k = bat[kk,:]\n",
    "        print(k)\n",
    "        batch_sel = np.array([uni_batches[i] for i in k])    \n",
    "        \n",
    "        ix = [] \n",
    "        for b in batch_sel:\n",
    "            if len(ix)<1:\n",
    "                ix = (batches==b)\n",
    "            else:\n",
    "                ix = (ix) | (batches==b)\n",
    "        ix = np.array(np.argwhere(ix==True)[:,0])\n",
    "        \n",
    "        ix_test_spec = np.array(list(set(range(spec.shape[0])) - set(ix)))\n",
    "\n",
    "        ### perform classification\n",
    "        model = cls.Classify(np.concatenate([spec[ix, :], spec[ix_test_spec, :]], axis=0), np.append(labels[ix], labels[ix_test_spec]), np.append(batches[ix], batches[ix_test_spec]))\n",
    "        pred = model.model(range(len(ix)), range(len(ix), len(ix)+len(ix_test_spec)))\n",
    "        acc = cls.cal_metric(labels[ix_test_spec], pred)\n",
    "        accs = np.append(accs, acc) \n",
    "        b_tests = np.append(b_tests, batch_sel)\n",
    "        methods = np.append(methods, 'org')\n",
    "        b_trains = np.append(b_trains, kk)\n",
    "        val_cors = np.append(val_cors, 2)\n",
    "        \n",
    "        ### prepare spectral pairs using spectra from same/different groups or batches\n",
    "        x, y, g = prep_training(spec[ix,:], labels[ix], batches[ix], n_pairs=40000) \n",
    "\n",
    "        ### zero paddings to make the dimension of the spectra fit to the network\n",
    "        downsampling = 2**args.n_down\n",
    "        n_org = x.shape[1]\n",
    "        n_res = (x.shape[1]//downsampling+1)*downsampling-x.shape[1]\n",
    "        if n_res>0: \n",
    "            x_end = np.fliplr(x[:, -n_res:])\n",
    "            y_end = np.fliplr(y[:, -n_res:])\n",
    "            x = np.concatenate([x, x_end], axis=1)\n",
    "            y = np.concatenate([y, y_end], axis=1)\n",
    "        res1 = x.shape[1]//downsampling-args.para_shape\n",
    "    \n",
    "        ### split data into training and testing (validation) for the network training\n",
    "        train_size = x.shape[0]//10*9\n",
    "        ix_train = np.random.choice(range(x.shape[0]), train_size, replace=False)\n",
    "        ix_test = list(set(range(x.shape[0])) - set(ix_train))\n",
    "\n",
    "        ### parameters for the VAE network\n",
    "        args.n_std = np.mean(np.std(snip(x[:, ix_wn], 10), axis=1))   ### estimate noise level from the data\n",
    "        args.input_size = (x.shape[1], 1)       \n",
    "        args.lr=0.00005\n",
    "        args.epochs = 100\n",
    "        model = vae.model_vae(args)    ### construct VAE network based on given parameters\n",
    "        \n",
    "        model.wn = wn.copy()\n",
    "        model.x = x.copy()\n",
    "        model.y = y.copy()\n",
    "        model.g = g.copy()\n",
    "        del x, y, g\n",
    "\n",
    "\n",
    "        ### train VAE network \n",
    "        model.train_vae(ix_train, ix_test, res1, ratio=1e-4, f_model='_weights1.h5')\n",
    "        if n_res>0: \n",
    "            x_end = np.fliplr(spec[:, -n_res:])\n",
    "            spec1 = np.concatenate([spec, x_end], axis=1)\n",
    "\n",
    "        ### test performance of the VAE by generating spectra of different similarity (controlled by 'cors')\n",
    "        ix_gen = np.random.choice(ix, size=300, replace=False)\n",
    "        y_gen, c_rea, c_gen, g_gen, b_gen = model.gen_cors(spec1[ix_gen, :], cors=np.asarray(np.linspace(90, 100, 20)/100.0), res1=res1)\n",
    "    \n",
    "        with open(dirname(abspath(os.getcwd())) + '/datasets/data_gen_all_' + str(kk) + '.pkl', 'wb') as f:\n",
    "            pickle.dump([y_gen, c_gen, c_rea, g_gen, b_gen], f)\n",
    "\n",
    "        ### plot the results of the generated spectra\n",
    "        ix_sb_sg = (b_gen>0.5) & (g_gen>0.5)\n",
    "        ix_db_sg = (b_gen<0.5) & (g_gen>0.5)\n",
    "        ix_sb_dg = (b_gen>0.5) & (g_gen<0.5)\n",
    "        ix_db_dg = (b_gen<0.5) & (g_gen<0.5)\n",
    "    \n",
    "        fig, ax = plt.subplots(2, 2, figsize=(10, 10))\n",
    "        c_gen_sb_sg = c_gen[ix_sb_sg]\n",
    "        c_gen_db_sg = c_gen[ix_db_sg]\n",
    "        c_gen_db_dg = c_gen[ix_db_dg]\n",
    "        c_gen_sb_dg = c_gen[ix_sb_dg]\n",
    "    \n",
    "        c_rea_sb_sg = c_rea[ix_sb_sg]\n",
    "        c_rea_db_sg = c_rea[ix_db_sg]\n",
    "        c_rea_db_dg = c_rea[ix_db_dg]\n",
    "        c_rea_sb_dg = c_rea[ix_sb_dg]\n",
    "    \n",
    "        for c in np.asarray(np.linspace(90, 100, 20)/100.0):\n",
    "            ix_plt = c_rea_sb_sg==c\n",
    "            ax[0, 0].boxplot(c_gen_sb_sg[ix_plt]*100, positions=[c*100], widths=0.1, showfliers=False)\n",
    "            ix_plt = c_rea_db_sg==c\n",
    "            ax[0, 1].boxplot(c_gen_db_sg[ix_plt]*100, positions=[c*100], widths=0.1, showfliers=False)\n",
    "            ix_plt = c_rea_db_dg==c\n",
    "            ax[1, 0].boxplot(c_gen_db_dg[ix_plt]*100, positions=[c*100], widths=0.1, showfliers=False)\n",
    "            ix_plt = c_rea_sb_dg==c\n",
    "            ax[1, 1].boxplot(c_gen_sb_dg[ix_plt]*100, positions=[c*100], widths=0.1, showfliers=False)\n",
    "        \n",
    "        ax[0, 0].axline((np.min(c_rea_sb_sg)*100, np.min(c_rea_sb_sg)*100), slope=1, linewidth=1, color='gray', linestyle='--')\n",
    "        ax[0, 0].set_xlabel('c-true')\n",
    "        ax[0, 0].set_ylabel('c-generated')\n",
    "        ax[0, 0].set_title('same group, same batch')\n",
    "        ax[0, 0].set_xticks([90, 95, 100], [90, 95, 100]) \n",
    "        # ax[0, 1].scatter(c_rea_db_sg*100, c_gen_db_sg*100)\n",
    "        ax[0, 1].axline((np.min(c_rea_db_sg)*100, np.min(c_rea_db_sg)*100), slope=1, linewidth=1, color='gray', linestyle='--')\n",
    "        ax[0, 1].set_xlabel('c-true')\n",
    "        ax[0, 1].set_ylabel('c-generated')\n",
    "        ax[0, 1].set_title('same group, different batch')\n",
    "        ax[0, 1].set_xticks([90, 95, 100], [90, 95, 100]) \n",
    "        ax[1, 0].axline((np.min(c_rea_db_dg)*100, np.min(c_rea_db_dg)*100), slope=1, linewidth=1, color='gray', linestyle='--')\n",
    "        ax[1, 0].set_xlabel('c-true')\n",
    "        ax[1, 0].set_ylabel('c-generated')\n",
    "        ax[1, 0].set_title('different group, different batch')\n",
    "        ax[1, 0].set_xticks([90, 95, 100], [90, 95, 100]) \n",
    "        ax[1, 1].axline((np.min(c_rea_sb_dg)*100, np.min(c_rea_sb_dg)*100), slope=1, linewidth=1, color='gray', linestyle='--')\n",
    "        ax[1, 1].set_xlabel('c-true')\n",
    "        ax[1, 1].set_ylabel('c-generated')\n",
    "        ax[1, 1].set_title('different group, same batch')\n",
    "        ax[1, 1].set_xticks([90, 95, 100], [90, 95, 100]) \n",
    "        plt.show()\n",
    "        \n",
    "        args.batch=False; args.lr=0.00001\n",
    "        args.input_size = (spec.shape[1], 1)   \n",
    "        args.epochs=200\n",
    "        m_nn = smsn.SiameseNetwork(args)        #### initialize class substance from SiameseNetwork class\n",
    "        m_nn.train_cls(spec[ix, :], dummy_y[ix, :], f_model='_weights1.h5')   #### train ordinary neural network\n",
    "\n",
    "\n",
    "        #### preparing spectral pairs to train the siamese network\n",
    "        n_pairs=40000\n",
    "        x, y, cb, g = prep_training_cls(spec[ix,:], labels[ix], batches[ix], n_pairs, cb_shape=args.batch_shape)\n",
    "        args.batch=False; args.group=False; args.lr=0.00001\n",
    "        args.epochs=100\n",
    "        m_smsn = smsn.SiameseNetwork(args)\n",
    "        m_smsn.train_snet(x, y, g, cb, f_model='_weights1.h5')    ### siamese network with normal loss\n",
    "            \n",
    "        args.batch=True; args.group=False; args.lr=0.00001\n",
    "        m_smsn_b = smsn.SiameseNetwork(args)\n",
    "        print('\\n siamese-b:\\n')\n",
    "        m_smsn_b.train_snet(x, y, g, cb, f_model='_weights1.h5')   ### siamese network with batch-based loss\n",
    "    \n",
    "        args.batch=False; args.group=True; args.lr=0.00001  \n",
    "        m_smsn_g = smsn.SiameseNetwork(args)\n",
    "        print('\\n siamese-b:\\n')\n",
    "        m_smsn_g.train_snet(x, y, g, cb, f_model='_weights1.h5')    ### siamese network with group-based loss\n",
    "    \n",
    "        args.batch=True; args.group=True; args.lr=0.00001   ### siamese network with group- and batch-based loss\n",
    "        m_smsn_gb = smsn.SiameseNetwork(args)\n",
    "        print('\\n siamese-b:\\n')\n",
    "        m_smsn_gb.train_snet(x, y, g, cb, f_model='_weights1.h5')\n",
    "        \n",
    "        smp_train = []\n",
    "        for l in np.unique(labels[ix]):\n",
    "            smp_train = np.append(smp_train, np.random.choice(ix[np.argwhere(labels[ix]==l)[:,0]], 10, replace=False))\n",
    "        smp_train = np.array(smp_train, dtype='int32')\n",
    "        \n",
    "        n_spec_gen = 20\n",
    "        for cc in np.asarray(np.linspace(90, 99, 9)):    #### generate spectra of different similarities as test data\n",
    "            #### generate spectra of different similarities as test data\n",
    "            y_gen, c_rea, c_gen, g_gen, b_gen = model.gen_mt(spec1[ix_gen,:], cors=np.asarray(np.linspace(cc, cc+1, n_spec_gen//4)/100.0), res1=res1)\n",
    "\n",
    "\n",
    "            #### pick spectra belonging to the same batch as input spectra for testing\n",
    "            spec_test = []\n",
    "            label_test = [] \n",
    "            batch_test = [] \n",
    "            for i in range(len(ix_gen)):\n",
    "                g_in_out = g_gen[(i*n_spec_gen):(i*n_spec_gen+n_spec_gen)]\n",
    "                b_in_out = b_gen[(i*n_spec_gen):(i*n_spec_gen+n_spec_gen)]\n",
    "                ix_pair = np.argwhere((g_in_out>0.5) & (b_in_out>0.5))[:,0]\n",
    "                spec_test.append(y_gen[i*n_spec_gen+ix_pair, :1376])\n",
    "                label_test = np.append(label_test, np.resize(labels[ix_gen[i]], len(ix_pair)))  \n",
    "                batch_test = np.append(batch_test, np.resize('gen_Batch', len(ix_pair)))  \n",
    "            \n",
    "            spec_test = np.row_stack(spec_test)\n",
    "    \n",
    "            c_mod = cls.Classify(np.concatenate([spec[ix, :], spec_test], axis=0), np.append(labels[ix], label_test), np.append(batches[ix], batch_test))\n",
    "            pred = c_mod.model(range(len(ix)), range(len(ix), len(ix)+len(batch_test)))\n",
    "            accs = np.append(accs, cls.cal_metric(label_test, pred)) \n",
    "            b_tests = np.append(b_tests, batch_sel)\n",
    "            methods = np.append(methods, 'sb')\n",
    "            b_trains = np.append(b_trains, kk)\n",
    "            val_cors = np.append(val_cors, cc)\n",
    "    \n",
    "            ### do model transfer based on MS\n",
    "            c_mod = cls.Classify(np.concatenate([spec[ix, :], spec_test], axis=0), np.append(labels[ix], label_test), np.append(batches[ix], batch_test), True)\n",
    "            pred = c_mod.model(range(len(ix)), range(len(ix), len(ix)+len(batch_test)))\n",
    "            accs = np.append(accs, cls.cal_metric(label_test, pred)) \n",
    "            methods = np.append(methods, 'sb-MS')\n",
    "            b_trains = np.append(b_trains, kk)\n",
    "            val_cors = np.append(val_cors, cc)\n",
    "            \n",
    "            ### do model transfer based on EMSC\n",
    "            interference, _ = cls.get_meanspec(np.concatenate([spec[ix, :], spec_test], axis=0), labels=np.append(np.resize('org', len(ix)), batch_test))\n",
    "\n",
    "            ### EMSC with one component\n",
    "            cur_spec_corr1 = emsc(np.concatenate([spec[ix, :], spec_test], axis=0), degree=2, interferent=interference, interf_pca=1)['corrected']                \n",
    "            c_mod = cls.Classify(cur_spec_corr1, np.append(labels[ix], label_test), np.append(batches[ix], batch_test))\n",
    "            pred = c_mod.model(range(len(ix)), range(len(ix), len(ix)+len(batch_test)))\n",
    "            accs = np.append(accs, cls.cal_metric(label_test, pred)) \n",
    "            methods = np.append(methods, 'sb-EMSC1')\n",
    "            b_trains = np.append(b_trains, kk)\n",
    "            val_cors = np.append(val_cors, cc)\n",
    "\n",
    "            ### EMSC with two component\n",
    "            cur_spec_corr2 = emsc(np.concatenate([spec[ix, :], spec_test], axis=0), degree=2, interferent=interference, interf_pca=2)['corrected']                \n",
    "            c_mod = cls.Classify(cur_spec_corr2, np.append(labels[ix], label_test), np.append(batches[ix], batch_test))\n",
    "            pred = c_mod.model(range(len(ix)), range(len(ix), len(ix)+len(batch_test)))\n",
    "            accs = np.append(accs, cls.cal_metric(label_test, pred)) \n",
    "            b_tests = np.append(b_tests, batch_sel)\n",
    "            methods = np.append(methods, 'sb-EMSC2')\n",
    "            b_trains = np.append(b_trains, kk)\n",
    "            val_cors = np.append(val_cors, cc)\n",
    "\n",
    "            ### prediction with ordinary neural network\n",
    "            pred_test, acc, min_acc, std_acc, method, b_test = m_nn.pred_cls(spec_test, label_test, batch_test, uni_labels)\n",
    "            accs = np.append(accs, np.mean(acc)) \n",
    "            methods = np.append(methods, 'sb-nn')\n",
    "            b_trains = np.append(b_trains, kk)\n",
    "            val_cors = np.append(val_cors, cc)\n",
    "    \n",
    "            ### prediction with siamese network\n",
    "            pred_test, acc, min_acc, std_acc, method, b_test = m_smsn.pred_snet(spec[smp_train,:], labels[smp_train], spec_test, label_test, batch_test)\n",
    "            accs = np.append(accs, np.mean(acc)) \n",
    "            methods = np.append(methods, 'sb-snet')\n",
    "            b_trains = np.append(b_trains, kk)\n",
    "            val_cors = np.append(val_cors, cc)\n",
    "\n",
    "            ### prediction with siamese network (batch-based loss)\n",
    "            pred_test, acc, min_acc, std_acc, method, b_test = m_smsn_b.pred_snet(spec[smp_train,:], labels[smp_train], spec_test, label_test, batch_test)\n",
    "            accs = np.append(accs, np.mean(acc)) \n",
    "            methods = np.append(methods, 'sb-snet-b')\n",
    "            b_trains = np.append(b_trains, kk)\n",
    "            val_cors = np.append(val_cors, cc)\n",
    "\n",
    "            ### prediction with siamese network (group-based loss)\n",
    "            pred_test, acc, min_acc, std_acc, method, b_test = m_smsn_g.pred_snet(spec[smp_train,:], labels[smp_train], spec_test, label_test, batch_test)\n",
    "            accs = np.append(accs, np.mean(acc)) \n",
    "            methods = np.append(methods, 'sb-snet-g')\n",
    "            b_trains = np.append(b_trains, kk)\n",
    "            val_cors = np.append(val_cors, cc)\n",
    "\n",
    "            ### prediction with siamese network (group- and batch-based loss)\n",
    "            pred_test, acc, min_acc, std_acc, method, b_test = m_smsn_gb.pred_snet(spec[smp_train,:], labels[smp_train], spec_test, label_test, batch_test)\n",
    "            accs = np.append(accs, np.mean(acc)) \n",
    "            methods = np.append(methods, 'sb-snet-gb')\n",
    "            b_trains = np.append(b_trains, kk)\n",
    "            val_cors = np.append(val_cors, cc)\n",
    "\n",
    "            ### prediction with siamese network on spectra with EMSC \n",
    "            pred_test, acc, min_acc, std_acc, method, b_test = m_smsn.pred_snet(spec[smp_train,:], labels[smp_train], cur_spec_corr1[len(ix):,:], label_test, batch_test)\n",
    "            accs = np.append(accs, np.mean(acc)) \n",
    "            methods = np.append(methods, 'sb-snet-EMSC1')\n",
    "            b_trains = np.append(b_trains, kk)\n",
    "            val_cors = np.append(val_cors, cc)\n",
    "\n",
    "            ### prediction with siamese network (batch-loss) on spectra with EMSC \n",
    "            pred_test, acc, min_acc, std_acc, method, b_test = m_smsn_b.pred_snet(spec[smp_train,:], labels[smp_train], cur_spec_corr1[len(ix):,:], label_test, batch_test)\n",
    "            accs = np.append(accs, np.mean(acc)) \n",
    "            methods = np.append(methods, 'sb-snet-b-EMSC1')\n",
    "            b_trains = np.append(b_trains, kk)\n",
    "            val_cors = np.append(val_cors, cc)\n",
    "\n",
    "            ### prediction with siamese network (group-loss) on spectra with EMSC \n",
    "            pred_test, acc, min_acc, std_acc, method, b_test = m_smsn_g.pred_snet(spec[smp_train,:], labels[smp_train], cur_spec_corr1[len(ix):,:], label_test, batch_test)\n",
    "            accs = np.append(accs, np.mean(acc)) \n",
    "            methods = np.append(methods, 'sb-snet-g-EMSC1')\n",
    "            b_trains = np.append(b_trains, kk)\n",
    "            val_cors = np.append(val_cors, cc)\n",
    "\n",
    "            ### prediction with siamese network (batch- and group-loss) on spectra with EMSC \n",
    "            pred_test, acc, min_acc, std_acc, method, b_test = m_smsn_gb.pred_snet(spec[smp_train,:], labels[smp_train], cur_spec_corr1[len(ix):,:], label_test, batch_test)\n",
    "            accs = np.append(accs, np.mean(acc)) \n",
    "            methods = np.append(methods, 'sb-snet-gb-EMSC1')\n",
    "            b_trains = np.append(b_trains, kk)\n",
    "            val_cors = np.append(val_cors, cc)\n",
    "    \n",
    "            #### pick spectra belonging to the different batch as input spectra for testing\n",
    "            spec_test = [] \n",
    "            label_test = [] \n",
    "            batch_test = [] \n",
    "            for i in range(len(ix_gen)):\n",
    "                g_in_out = g_gen[(i*n_spec_gen):(i*n_spec_gen+n_spec_gen)]\n",
    "                b_in_out = b_gen[(i*n_spec_gen):(i*n_spec_gen+n_spec_gen)]\n",
    "                ix_pair = np.argwhere((g_in_out>0.5) & (b_in_out<0.5))[:,0]\n",
    "                spec_test.append(y_gen[i*n_spec_gen+ix_pair, :1376])\n",
    "                label_test = np.append(label_test, np.resize(labels[ix_gen[i]], len(ix_pair)))  \n",
    "                batch_test = np.append(batch_test, np.resize('gen_Batch', len(ix_pair)))  \n",
    "            \n",
    "            spec_test = np.row_stack(spec_test)\n",
    "            \n",
    "            c_mod = cls.Classify(np.concatenate([spec[ix, :], spec_test], axis=0), np.append(labels[ix], label_test), np.append(batches[ix], batch_test))\n",
    "            pred = c_mod.model(range(len(ix)), range(len(ix), len(ix)+len(batch_test)))\n",
    "            accs = np.append(accs, cls.cal_metric(label_test, pred)) \n",
    "            b_tests = np.append(b_tests, batch_sel)\n",
    "            methods = np.append(methods, 'db')\n",
    "            b_trains = np.append(b_trains, kk)\n",
    "            val_cors = np.append(val_cors, cc)\n",
    "    \n",
    "            ### do model transfer based on MS\n",
    "            c_mod = cls.Classify(np.concatenate([spec[ix, :], spec_test], axis=0), np.append(labels[ix], label_test), np.append(batches[ix], batch_test), True)\n",
    "            pred = c_mod.model(range(len(ix)), range(len(ix), len(ix)+len(batch_test)))\n",
    "            accs = np.append(accs, cls.cal_metric(label_test, pred)) \n",
    "            b_tests = np.append(b_tests, batch_sel)\n",
    "            methods = np.append(methods, 'db-MS')\n",
    "            b_trains = np.append(b_trains, kk)\n",
    "            val_cors = np.append(val_cors, cc)\n",
    "            \n",
    "            ### do model transfer based on EMSC\n",
    "            interference, _ = cls.get_meanspec(np.concatenate([spec[ix, :], spec_test], axis=0), labels=np.append(np.resize('org', len(ix)), batch_test))\n",
    "            ### EMSC with one component\n",
    "            cur_spec_corr1 = emsc(np.concatenate([spec[ix, :], spec_test], axis=0), degree=2, interferent=interference, interf_pca=1)['corrected']                \n",
    "            c_mod = cls.Classify(cur_spec_corr1, np.append(labels[ix], label_test), np.append(batches[ix], batch_test))\n",
    "            pred = c_mod.model(range(len(ix)), range(len(ix), len(ix)+len(batch_test)))\n",
    "            accs = np.append(accs, cls.cal_metric(label_test, pred)) \n",
    "            methods = np.append(methods, 'db-EMSC1')\n",
    "            b_trains = np.append(b_trains, kk)\n",
    "            val_cors = np.append(val_cors, cc)\n",
    "            \n",
    "            ### EMSC with two component\n",
    "            cur_spec_corr2 = emsc(np.concatenate([spec[ix, :], spec_test], axis=0), degree=2, interferent=interference, interf_pca=2)['corrected']                \n",
    "            c_mod = cls.Classify(cur_spec_corr2, np.append(labels[ix], label_test), np.append(batches[ix], batch_test))\n",
    "            pred = c_mod.model(range(len(ix)), range(len(ix), len(ix)+len(batch_test)))\n",
    "            accs = np.append(accs, cls.cal_metric(label_test, pred)) \n",
    "            methods = np.append(methods, 'db-EMSC2')\n",
    "            b_trains = np.append(b_trains, kk)\n",
    "            val_cors = np.append(val_cors, cc)\n",
    "            \n",
    "            ### prediction with ordinary neural network\n",
    "            pred_test, acc, min_acc, std_acc, method, b_test = m_nn.pred_cls(spec_test, label_test, batch_test, uni_labels)\n",
    "            accs = np.append(accs, np.mean(acc)) \n",
    "            methods = np.append(methods, 'db-nn')\n",
    "            b_trains = np.append(b_trains, kk)\n",
    "            val_cors = np.append(val_cors, cc)\n",
    "    \n",
    "            ### prediction with siamese network\n",
    "            pred_test, acc, min_acc, std_acc, method, b_test = m_smsn.pred_snet(spec[smp_train,:], labels[smp_train], spec_test, label_test, batch_test)\n",
    "            accs = np.append(accs, np.mean(acc)) \n",
    "            methods = np.append(methods, 'db-snet')\n",
    "            b_trains = np.append(b_trains, kk)\n",
    "            val_cors = np.append(val_cors, cc)\n",
    "    \n",
    "            ### prediction with siamese network (batch-loss)\n",
    "            pred_test, acc, min_acc, std_acc, method, b_test = m_smsn_b.pred_snet(spec[smp_train,:], labels[smp_train], spec_test, label_test, batch_test)\n",
    "            accs = np.append(accs, np.mean(acc)) \n",
    "            methods = np.append(methods, 'db-snet-b')\n",
    "            b_trains = np.append(b_trains, kk)\n",
    "            val_cors = np.append(val_cors, cc)\n",
    "    \n",
    "            ### prediction with siamese network (group-loss)\n",
    "            pred_test, acc, min_acc, std_acc, method, b_test = m_smsn_g.pred_snet(spec[smp_train,:], labels[smp_train], spec_test, label_test, batch_test)\n",
    "            accs = np.append(accs, np.mean(acc)) \n",
    "            methods = np.append(methods, 'db-snet-g')\n",
    "            b_trains = np.append(b_trains, kk)\n",
    "            val_cors = np.append(val_cors, cc)\n",
    "    \n",
    "            ### prediction with siamese network (batch- and group-loss)\n",
    "            pred_test, acc, min_acc, std_acc, method, b_test = m_smsn_gb.pred_snet(spec[smp_train,:], labels[smp_train], spec_test, label_test, batch_test)\n",
    "            accs = np.append(accs, np.mean(acc)) \n",
    "            methods = np.append(methods, 'db-snet-gb')\n",
    "            b_trains = np.append(b_trains, kk)\n",
    "            val_cors = np.append(val_cors, cc)\n",
    "    \n",
    "            ### prediction with siamese network after EMSC correction\n",
    "            pred_test, acc, min_acc, std_acc, method, b_test = m_smsn.pred_snet(spec[smp_train,:], labels[smp_train], cur_spec_corr1[len(ix):,:], label_test, batch_test)\n",
    "            accs = np.append(accs, np.mean(acc)) \n",
    "            methods = np.append(methods, 'db-snet-EMSC1')\n",
    "            b_trains = np.append(b_trains, kk)\n",
    "            val_cors = np.append(val_cors, cc)\n",
    "    \n",
    "            ### prediction with siamese network (batch-loss) after EMSC correction\n",
    "            pred_test, acc, min_acc, std_acc, method, b_test = m_smsn_b.pred_snet(spec[smp_train,:], labels[smp_train], cur_spec_corr1[len(ix):,:], label_test, batch_test)\n",
    "            accs = np.append(accs, np.mean(acc)) \n",
    "            methods = np.append(methods, 'db-snet-b-EMSC1')\n",
    "            b_trains = np.append(b_trains, kk)\n",
    "            val_cors = np.append(val_cors, cc)\n",
    "    \n",
    "            ### prediction with siamese network (group-loss) after EMSC correction\n",
    "            pred_test, acc, min_acc, std_acc, method, b_test = m_smsn_g.pred_snet(spec[smp_train,:], labels[smp_train], cur_spec_corr1[len(ix):,:], label_test, batch_test)\n",
    "            accs = np.append(accs, np.mean(acc)) \n",
    "            methods = np.append(methods, 'db-snet-g-EMSC1')\n",
    "            b_trains = np.append(b_trains, kk)\n",
    "            val_cors = np.append(val_cors, cc)\n",
    "    \n",
    "            ### prediction with siamese network (batch- and group-loss) after EMSC correction\n",
    "            pred_test, acc, min_acc, std_acc, method, b_test = m_smsn_gb.pred_snet(spec[smp_train,:], labels[smp_train], cur_spec_corr1[len(ix):,:], label_test, batch_test)\n",
    "            accs = np.append(accs, np.mean(acc)) \n",
    "            methods = np.append(methods, 'db-snet-gb-EMSC1')\n",
    "            b_trains = np.append(b_trains, kk)\n",
    "            val_cors = np.append(val_cors, cc)\n",
    "    \n",
    "    with open('accs_mt1_gen_'+str(n_b)+'_batch.pkl', 'wb') as f:\n",
    "        pickle.dump([accs, methods, b_trains, val_cors], f)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5661833-47dd-430d-a6dd-ec711aaeed46",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
